{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gonzalo/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "from gpflow.likelihoods import Gaussian\n",
    "from gpflow.kernels import RBF, White\n",
    "from gpflow.mean_functions import Constant\n",
    "from gpflow.models.sgpr import SGPR, GPRFITC\n",
    "from gpflow.models.svgp import SVGP\n",
    "from gpflow.models.gpr import GPR\n",
    "from gpflow.training import AdamOptimizer, ScipyOptimizer\n",
    "\n",
    "from scipy.cluster.vq import kmeans2\n",
    "from scipy.stats import norm\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "from doubly_stochastic_dgp.dgp import DGP\n",
    "from datasets import Datasets\n",
    "datasets = Datasets(data_path='data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 455, D: 13, Ns: 51\n"
     ]
    }
   ],
   "source": [
    "data = datasets.all_datasets['boston'].get_data()\n",
    "X, Y, Xs, Ys, Y_std, Y_mean = [data[_] for _ in ['X', 'Y', 'Xs', 'Ys', 'Y_std', 'Y_mean']]\n",
    "print('N: {}, D: {}, Ns: {}'.format(X.shape[0], X.shape[1], Xs.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is normalized?: True\n",
      "1.0751266056104234\n",
      "[7.79674467]\n"
     ]
    }
   ],
   "source": [
    "print(\"Is normalized?: {}\".format(np.allclose(0,np.mean(X))))\n",
    "print(np.std(X))\n",
    "print(Y_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dgp(X, Y, Z, L):\n",
    "    D = X.shape[1]\n",
    "    \n",
    "    # the layer shapes are defined by the kernel dims, so here all hidden layers are D dimensional \n",
    "    kernels = []\n",
    "    for l in range(L):\n",
    "        kernels.append(RBF(D))\n",
    "        \n",
    "    # between layer noise (doesn't actually make much difference but we include it anyway)\n",
    "    for kernel in kernels[:-1]:\n",
    "        kernel += White(D, variance=1e-5) \n",
    "        \n",
    "    mb = 1000 if X.shape[0] > 1000 else None \n",
    "    model = DGP(X, Y, Z, kernels, Gaussian(), num_samples=10, minibatch_size=mb)\n",
    "\n",
    "    # start the inner layers almost deterministically \n",
    "    for layer in model.layers[:-1]:\n",
    "        layer.q_sqrt = layer.q_sqrt.value * 1e-5\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_100 = kmeans2(X, 100, minit='points')[0]\n",
    "m_dgp2 = make_dgp(X, Y, Z_100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "AdamOptimizer(0.01).minimize(m_dgp2, maxiter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_assess(model, X, Y):\n",
    "    n_batches = max(int(X.shape[0]/1000.), 1)\n",
    "    lik, sq_diff = [], []\n",
    "    for X_batch, Y_batch in zip(np.array_split(X, n_batches), np.array_split(Y, n_batches)):\n",
    "        l, sq = assess_sampled(model, X_batch, Y_batch)\n",
    "        lik.append(l)\n",
    "        sq_diff.append(sq)\n",
    "    lik = np.concatenate(lik, 0)\n",
    "    sq_diff = np.array(np.concatenate(sq_diff, 0), dtype=float)\n",
    "    return np.average(lik), np.average(sq_diff)**0.5\n",
    "\n",
    "S = 100\n",
    "def assess_sampled(model, X_batch, Y_batch):\n",
    "    m, v = model.predict_y(X_batch, S)\n",
    "    S_lik = np.sum(norm.logpdf(Y_batch*Y_std, loc=m*Y_std, scale=Y_std*v**0.5), 2)\n",
    "    lik = logsumexp(S_lik, 0, b=1/float(S))\n",
    "    \n",
    "    mean = np.average(m, 0)\n",
    "    sq_diff = ((mean - Y_batch)**2)\n",
    "    return lik, sq_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-Likelihood: -2.2046342204322613 RMSE: 0.27152198551870377\n"
     ]
    }
   ],
   "source": [
    "lik, rmse = batch_assess(m_dgp2, Xs, Ys)\n",
    "print(\"Log-Likelihood: {} RMSE: {}\".format(lik, rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, v = m_dgp2.predict_y(Xs, S)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.20266375]\n"
     ]
    }
   ],
   "source": [
    "# Likelihood con mi metodo\n",
    "log_num_samples = np.log(S)  \n",
    "logpdf = norm.logpdf(Ys*Y_std, loc=m*Y_std, scale=Y_std*v**0.5)    \n",
    "print(np.mean(logsumexp(logpdf, 0) - log_num_samples, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_unnormalized = Ys * Y_std + Y_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.20266375]\n"
     ]
    }
   ],
   "source": [
    "# Likelihood con mi metodo\n",
    "log_num_samples = np.log(S)   \n",
    "logpdf = norm.logpdf(y_unnormalized, loc=m*Y_std+Y_mean, scale=Y_std*v**0.5)    \n",
    "print(np.mean(logsumexp(logpdf, 0) - log_num_samples, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27085827732633144\n"
     ]
    }
   ],
   "source": [
    "# RMSE EXACTO\n",
    "m, v = m_dgp2.predict_y(Xs, S)\n",
    "pred = np.mean(m, 0)\n",
    "rmse = np.sqrt(np.mean((pred - (y_unnormalized - Y_mean)/Y_std)**2))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27085827732633144"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error((y_unnormalized - Y_mean)/Y_std, pred)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
